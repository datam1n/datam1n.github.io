@inproceedings{Minier2007,
abstract = {In recent years several models have been proposed for text categorization. Within this, one of the widely applied models is the vector space model (VSM), where independence between indexing terms, usually words, is assumed. Since training corpora sizes are relatively small - compared to ≈ ∞ what would be required for a realistic number of words - the generalization power of the learning algorithms is low. It is assumed that a bigger text corpus can boost the representation and hence the learning process. Based on the work of Gabrilovich and Markovitch [6], we incorporate Wikipedia articles into the system to give word distributional representation for documents. The extension with this new corpus causes dimensionality increase, therefore clustering of features is needed. We use Latent Semantic Analysis (LSA), Kernel Principal Component Analysis (KPCA) and Kernel Canonical Correlation Analysis (KCCA) and present results for these experiments on the Reuters corpus. {\textcopyright} 2008 IEEE.},
author = {Minier, Zsolt and Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
booktitle = {Proceedings - 9th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2007},
doi = {10.1109/SYNASC.2007.8},
isbn = {0769530788},
title = {{Wikipedia-based Kernels for text categorization}},
year = {2007}
}
@inproceedings{Bodo2012,
abstract = {Large databases become more and more common in (supervised) learning scenarios, containing hundred thousands or even millions of training examples. Finding the k-nearest neighbors (k-NN) of a point from a dataset, however, requires to compare the point to every training example. Locality-sensitive hashing (LSH) [11], [7], [3] hashes the dataset into buckets such that, with high probability, similar examples are grouped together, thus providing a sub-linear search time for neighbors. However, linear k-NN is sometimes not enough; the Euclidean distance does not always capture important data properties, therefore kernels are used to map data into a - possibly higher dimensional - feature space and perform the k-NN search there. To kernelize the LSH from [3], the most important question to be answered is how to generate random normally distributed vectors in the feature space. In this paper we present an improved kernel LSH technique, a modified version of the kLSH algorithm proposed in [12]. We compute the pre-images of the random feature space vectors to save important computational resources. Our proposal of pre-image calculation is interesting, because no additional intrinsic computations are required. Furthermore, for positive definite kernel functions we propose two inequalities to speed up searching. {\textcopyright} 2012 IEEE.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2012.6252742},
isbn = {9781467314909},
title = {{Improving kernel locality-sensitive hashing using pre-images and bounds}},
year = {2012}
}
@article{Bodo2014,
abstract = {Spectral hashing assigns binary hash keys to data points. This is accomplished via thresholding the eigenvectors of the graph Laplacian and obtaining binary codewords. While calculation for inputs in the training set is straightforward, an intriguing and difficult problem is how to compute the hash codewords for previously unseen data. For specific problems we propose linear scalar products as similarity measures and analyze the performance of the algorithm. We implement the linear algorithm and provide an inductive - generative - formula that leads to a codeword generation method similar to random hyperplane-based locality-sensitive hashing for a new data point. {\textcopyright} 2014 Elsevier B.V.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
doi = {10.1016/j.neucom.2013.11.039},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Nearest-neighbor search,Spectral clustering,Spectral hashing},
title = {{Linear spectral hashing}},
volume = {141},
year = {2014}
}
@inproceedings{Bodo2014a,
abstract = {Hashing methods for fast approximate nearest-neighbor search are getting more and more attention with the excessive growth of the available data today. Embedding the points into the Hamming space is an important question of the hashing process. Analogously to machine learning there exist unsupervised, supervised and semi-supervised hashing methods. In this paper we propose a generic procedure to extend unsupervised codeword generators using error correcting codes and semisupervised classifiers. To show the effectiveness of the method we combine linear spectral hashing and two semi-supervised algorithms in the experiments.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
booktitle = {22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2014 - Proceedings},
isbn = {9782874190957},
title = {{Augmented hashing for semi-supervised scenarios}},
year = {2014}
}
@book{Bodo2017,
abstract = {{\textcopyright} 2017 The authors and IOS Press. All rights reserved. In recent years, there has been a growing interest in applying deep learning techniques for automatic generation of software. To achieve this ambitious objective, a number of smaller research goals need to be reached, one of which is automatic categorization of software, used in numerous tasks of software intelligence. We present here an approach to this problem using a set of low-level features derived from lexical analysis of software code. We compare different feature sets for categorizing software and also apply different supervised machine learning algorithms to perform the classification task. The representation allows us to identify the most relevant libraries used for each class, and we use the best-performing classifier to accomplish this. We evaluate our approach by applying it to categorize popular Python projects from Github.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Indurkhya, Bipin},
booktitle = {Frontiers in Artificial Intelligence and Applications},
doi = {10.3233/978-1-61499-800-6-88},
isbn = {9781614997993},
issn = {09226389},
keywords = {Distributional features,Feature selection,Software categorization,Software intelligence,Text categorization},
title = {{Software categorization using low-level distributional features}},
volume = {297},
year = {2017}
}
@inproceedings{Bodo2013,
abstract = {Spectral hashing assigns binary hash keys to data points. This is accomplished via thresholding the eigenvectors of the graph Laplacian and obtaining binary codewords. While calculation for inputs in the training set is straightforward, an intriguing and difficult problem is how to compute the hash codewords for unseen data. A second problem we address is the computational difficulties when using the Gaussian similarity measure in spectral hashing: for specific problems - mainly the processing of large text databases - we propose linear scalar products as similarity measures and analyze the performance of the algorithm. We implement the linear algorithm and provide an inductive - generative - formula that leads to a prediction method similar to locality-sensitive hashing for a new data point. Experiments on document retrieval show promising results.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
booktitle = {ESANN 2013 proceedings, 21st European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
isbn = {9782874190810},
title = {{Linear spectral hashing}},
year = {2013}
}
@article{Bodo2010,
abstract = {Recently semi-supervised methods gained increasing attention and many novel semi-supervised learning algorithms have been proposed. These methods exploit the information contained in the usually large unlabeled data set in order to improve classification or generalization performance. Using data-dependent kernels for kernel machines one can build semi-supervised classifiers by building the kernel in such a way that feature space dot products incorporate the structure of the data set. In this paper we propose two such methods: one using specific hierarchical clustering, and another kernel for reweighting an arbitrary base kernel taking into account the cluster structure of the data. {\textcopyright} 2006-2010 by CCC Publications.},
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
doi = {10.15837/ijccc.2010.4.2496},
issn = {18419844},
journal = {International Journal of Computers, Communications and Control},
keywords = {Clustering,Kernel methods,Semi-supervised learning},
number = {4},
title = {{Hierarchical and reweighting cluster kernels for semi-supervised learning}},
volume = {5},
year = {2010}
}
@inproceedings{Bodo2008,
abstract = {Semi-supervised learning became an important subdonlain of machine learning in the last years. These rnethods try to exploit the information provided by the large and easily gathered unlabeled data besides the labeled training set. Analogously, many semi-supervised kernels appeared which determine similarity in feature space considering also the unlabeled data points. In this paper we propose a novel kemel construction algorithm jar supervised and semi-supervised learning, which actually constitutes a general frame of semi-supervised kernel construction. The technique is based on the cluster assumption: we cluster the labeled and unlabeled data by an agglomerative clustering technique, and then we use the linkage distances induced by the clustering hierarchy to construct our kernel. The hierarchical cluster kernel is then compared to other existing techniques and evaluated on synthetic and real data sets. {\textcopyright}2008 IEEE.},
author = {Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {Proceedings - 2008 IEEE 4th International Conference on Intelligent Computer Communication and Processing, ICCP 2008},
doi = {10.1109/ICCP.2008.4648348},
isbn = {9781424426737},
title = {{Hierarchical cluster kernels for supervised and semi-supervised learning}},
year = {2008}
}
@incollection{jakab2015sparse,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {Artificial Neural Networks},
pages = {295--314},
publisher = {Springer},
title = {{Sparse approximations to value functions in reinforcement learning}},
url = {https://link.springer.com/chapter/10.1007/978-3-319-09903-3{\_}14},
year = {2015}
}
@inproceedings{jakab2012reinforcement,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {The 2012 International Joint Conference on Neural Networks (IJCNN)},
organization = {IEEE},
pages = {1--8},
title = {{Reinforcement learning with guided policy search using Gaussian processes}},
url = {https://ieeexplore.ieee.org/document/6252509},
year = {2012}
}
@inproceedings{bodo2007text,
author = {Bod{\'{o}}, Zal{\'{a}}n and Minier, Zsolt and Csat{\'{o}}, Lehel},
booktitle = {Proceedings of the International Conference on Knowledge Engineering, Principles and Techniques},
pages = {66--72},
title = {{Text categorization experiments using Wikipedia}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2007-kept/207-BodoMinierCsato.pdf},
year = {2007}
}
@phdthesis{bodo2009phd,
author = {Bod{\'{o}}, Zal{\'{a}}n},
school = {Faculty of Mathematics and Computer Science, Babeș-Bolyai University},
title = {{Semi-supervised Learning with Kernels}},
url = {http://www.cs.ubbcluj.ro/{~}zbodo/thesis/thesis.pdf},
year = {2009}
}
@book{csato2008neuralis,
author = {Csat{\'{o}}, Lehel and Bod{\'{o}}, Zal{\'{a}}n},
publisher = {Presa Universitară Clujeană},
title = {{Neur{\'{a}}lis h{\'{a}}l{\'{o}}k {\'{e}}s a g{\'{e}}pi tanul{\'{a}}s m{\'{o}}dszerei}},
year = {2008}
}
@article{jakab2011geodesic,
author = {Jakab, Hunor},
journal = {Studia Universitatis Babeș-Bolyai Informatica},
number = {3},
pages = {51--56},
title = {{Geodesic distance-based kernel construction for gaussian process value function approximation}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2011-3/c63-Jakab.pdf},
volume = {LVI},
year = {2011}
}
@inproceedings{bodo2008supervised,
author = {Bod{\'{o}}, Zal{\'{a}}n and Minier, Zsolt},
booktitle = {Proceedings of the 7th Joint Conference on Mathematics and Computer Science},
pages = {79--92},
title = {{On supervised and semi-supervised k-nearest neighbor algorithms}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2008-2/07-Bodo.pdf},
volume = {53},
year = {2008}
}
@inproceedings{jakab2010using,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {8th International Conference on Applied Informatics (ICAI)},
pages = {87--94},
title = {{Using Gaussian processes for variance reduction in policy gradient algorithms}},
url = {http://icai.ektf.hu/pdf/ICAI2010-vol1-pp87-94.pdf},
year = {2010}
}
@inproceedings{jakab2011improving,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {International Conference on Artificial Neural Networks},
organization = {Springer},
pages = {221--228},
title = {{Improving Gaussian process value function approximation in policy gradient algorithms}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-21738-8{\_}29},
year = {2011}
}
@inproceedings{bocsi2010nonparam,
address = {Komarno, Slovakia},
author = {B{\'{o}}csi, Botond and Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {Proceedings of the 8th Joint Conference on Mathematics and Computer Science},
title = {{Nonparametric methods in robotics}},
year = {2010}
}
@inproceedings{jakab2012manifold,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {ESANN},
pages = {579--584},
title = {{Manifold-based non-parametric learning of action-value functions.}},
url = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2012-179.pdf},
year = {2012}
}
@inproceedings{bocsi2013alignment,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel and Peters, Jan},
booktitle = {The 2013 international joint conference on neural networks (IJCNN)},
organization = {IEEE},
pages = {1--7},
title = {{Alignment-based transfer learning for robot models}},
url = {https://ieeexplore.ieee.org/abstract/document/6706721/},
year = {2013}
}
@inproceedings{jakab2009qlearning,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {Proceedings of KEPT 2009},
pages = {175--178},
title = {{Q-learning and policy gradient methods}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2009-kept/Studia-2009-Kept-2-KPD.pdf},
year = {2009}
}
@inproceedings{bocsi2009dirichlet,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel},
booktitle = {ESANN},
pages = {491--496},
title = {{Dirichlet process-based component detection in state-space models.}},
url = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2009-107.pdf},
year = {2009}
}
@inproceedings{bocsi2011learning,
author = {B{\'{o}}csi, Botond and Nguyen-Tuong, Duy and Csat{\'{o}}, Lehel and Schoelkopf, Bernhard and Peters, Jan},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
organization = {IEEE},
pages = {698--703},
title = {{Learning inverse kinematics with structured prediction}},
url = {http://is.tuebingen.mpg.de/fileadmin/user{\_}upload/files/publications/2011/IROS-2011-Bocsi.pdf},
year = {2011}
}
@inproceedings{minier2006segmentation,
author = {Minier, Zsolt and Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
booktitle = {Proceedings of the 2nd International Conference on Intelligent Computer Communication and Processing},
pages = {53--59},
title = {{Segmentation-based feature selection for text categorization}},
year = {2006}
}
@inproceedings{bocsi2012learning,
author = {B{\'{o}}csi, Botond and Hennig, Philipp and Csat{\'{o}}, Lehel and Peters, Jan},
booktitle = {2012 IEEE International Conference on Robotics and Automation},
organization = {IEEE},
pages = {259--264},
title = {{Learning tracking control with forward models}},
url = {http://is.tuebingen.mpg.de/fileadmin/user{\_}upload/files/publications/2012/ICRA-2012-Bocsi.pdf},
year = {2012}
}
@article{bodo2015note,
author = {Bod{\'{o}}, Zal{\'{a}}n and Csat{\'{o}}, Lehel},
journal = {Acta Universitatis Sapientiae, Informatica},
number = {1},
pages = {18--30},
publisher = {Sciendo},
title = {{A note on label propagation for semi-supervised learning}},
url = {https://content.sciendo.com/downloadpdf/journals/ausi/7/1/article-p18.pdf},
volume = {7},
year = {2015}
}
@inproceedings{bodo2009kept,
author = {Bod{\'{o}}, Zal{\'{a}}n and Minier, Zsolt},
booktitle = {Proceedings of KEPT 2009},
pages = {159--162},
title = {{Semi-supervised learning with SVMs}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2009-kept/Studia-2009-Kept-2-KPD.pdf},
year = {2009}
}
@inproceedings{bodo2011active,
author = {Bod{\'{o}}, Zal{\'{a}}n and Minier, Zsolt and Csat{\'{o}}, Lehel},
booktitle = {Active Learning and Experimental Design Workshop in Conjunction with AISTATS 2010},
pages = {127--139},
title = {{Active learning with clustering}},
url = {http://www.jmlr.org/proceedings/papers/v16/bodo11a/bodo11a.pdf},
year = {2011}
}
@inproceedings{jakab2013novel,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {International Conference on Artificial Neural Networks},
organization = {Springer},
pages = {170--177},
title = {{Novel feature selection and kernel-based value approximation method for reinforcement learning}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-40728-4{\_}22},
year = {2013}
}
@inproceedings{bocsi2013hessian,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel},
booktitle = {International Conference on Artificial Neural Networks},
organization = {Springer},
pages = {1--8},
title = {{Hessian corrected input noise models}},
url = {https://link.springer.com/chapter/10.1007/978-3-642-40728-4{\_}1},
year = {2013}
}
@inproceedings{minier2007kernel,
author = {Minier, Zsolt and Csat{\'{o}}, Lehel},
booktitle = {ESANN},
pages = {349--354},
title = {{Kernel PCA based clustering for inducing features in text categorization.}},
url = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2007-97.pdf},
year = {2007}
}
@inproceedings{bocsi2008visual,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel},
booktitle = {2008 4th International Conference on Intelligent Computer Communication and Processing},
organization = {IEEE},
pages = {269--274},
title = {{Visual tracking with filtering algorithms}},
year = {2008}
}
@article{bocsi2014indirect,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel and Peters, Jan},
journal = {Advanced Robotics},
number = {9},
pages = {589--599},
publisher = {Taylor {\&} Francis},
title = {{Indirect robot model learning for tracking control}},
volume = {28},
year = {2014}
}
@inproceedings{bocsi2014simulation,
author = {B{\'{o}}csi, Botond and Jakab, Hunor and Csat{\'{o}}, Lehel},
booktitle = {2014 16th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing},
organization = {IEEE},
pages = {189--195},
title = {{Simulation-Extrapolation Gaussian Processes for Input Noise Modeling}},
year = {2014}
}
@inproceedings{minier2009kept,
author = {Minier, Zsolt},
booktitle = {Proceedings of KEPT 2009},
pages = {61--64},
title = {{Feature Selection in Text Categorization Using l1-Regularized SVMs}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2009-kept/Studia-2009-Kept-2-KPD.pdf},
year = {2009}
}
@inproceedings{csato2009kept,
author = {Csat{\'{o}}, Lehel and Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {Proceedings of KEPT 2009},
pages = {127--130},
title = {{Decomposition methods for label propagation}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2009-kept/Studia-2009-Kept-2-KPD.pdf},
year = {2009}
}
@incollection{bodo2014gepitanulas,
author = {Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {T{\'{i}}z {\'{e}}ves az ELTE E{\"{o}}tv{\"{o}}s J{\'{o}}zsef Collegium Informatikai Műhelye},
pages = {61--78},
title = {{G{\'{e}}pi tanul{\'{a}}s gr{\'{a}}fokkal}},
url = {http://honlap.eotvos.elte.hu/wp-content/uploads/2016/02/informatikusok.pdf},
year = {2014}
}
@inproceedings{jakab2011non,
author = {Jakab, Hunor and B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel},
booktitle = {The 8th Joint Conference on Mathematics and Computer Science (MACS2010)},
pages = {235--248},
title = {{Non-parametric value function approximation in robotics}},
year = {2011}
}
@article{bocsi2011studia,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel},
journal = {Studia Universitatis Babeș-Bolyai Informatica},
number = {2},
pages = {61--67},
title = {{Reinforcement Learning Algorithms in Robotics}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/contents/2011-2/b13-BocsiCsato.pdf},
volume = {LVI},
year = {2011}
}
@techreport{jakab2011techrep,
author = {Jakab, Hunor and Csat{\'{o}}, Lehel},
institution = {Faculty of Mathematics and Computer Science, Babeș-Bolyai University},
title = {{Guided exploration in gradient based policy search with Gaussian}},
year = {2011}
}
@inproceedings{jakab2011fmtu,
address = {Cluj-Napoca},
author = {Jakab, Hunor},
booktitle = {XVI. Fiatal Műszakiak Tudom{\'{a}}nyos {\"{U}}l{\'{e}}sszaka},
title = {{A lengő Atwood g{\'{e}}p vez{\'{e}}rl{\'{e}}se megerős{\'{i}}t{\'{e}}ses tanul{\'{a}}ssal}},
year = {2011}
}
@inproceedings{szenkovits2016optimizing,
author = {Szenkovits, Annam{\'{a}}ria and Gask{\'{o}}, No{\'{e}}mi and Jakab, Hunor},
booktitle = {2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
organization = {IEEE},
pages = {214--218},
title = {{Optimizing test input generation for reactive systems with an adaptive differential evolution}},
url = {https://ieeexplore.ieee.org/document/7829614},
year = {2016}
}
@book{bodo2014fordprog,
address = {Kolozsv{\'{a}}r},
author = {Bod{\'{o}}, Zal{\'{a}}n},
publisher = {Erd{\'{e}}lyi M{\'{u}}zeum-Egyes{\"{u}}let},
title = {{Ford{\'{i}}t{\'{o}}programok szerkeszt{\'{e}}se Flex {\'{e}}s Bison seg{\'{i}}ts{\'{e}}g{\'{e}}vel}},
url = {https://eda.eme.ro/handle/10598/28426},
year = {2014}
}
@article{bodo2017hybrid,
author = {Bod{\'{o}}, ZAL{\'{A}}N and Csat{\'{o}}, LEHEL},
journal = {Studia Universitatis Babeș-Bolyai Informatica},
number = {2},
pages = {5--16},
title = {{A hybrid approach for scholarly information extraction}},
url = {http://www.cs.ubbcluj.ro/{~}studia-i/journal/journal/article/view/10/9},
volume = {62},
year = {2017}
}
@article{bodo2018connecting,
author = {Bod{\'{o}}, Zal{\'{a}}n and Szil{\'{a}}gyi, Eszter},
journal = {Acta Universitatis Sapientiae, Informatica},
number = {2},
pages = {158--182},
publisher = {Sciendo},
title = {{Connecting the Last. fm Dataset to LyricWiki and MusicBrainz. Lyrics-based experiments in genre classification}},
url = {http://www.acta.sapientia.ro/acta-info/C10-2/info102-2.pdf},
volume = {10},
year = {2018}
}
@inproceedings{bodo2018citeseerx,
author = {Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
organization = {IEEE},
pages = {230--236},
title = {{A CiteSeerX-Based Dataset for Record Linkage and Metadata Extraction}},
url = {https://ieeexplore.ieee.org/abstract/document/8750698/},
year = {2018}
}
@inproceedings{sulyok2019impact,
author = {Sulyok, Csaba and Harte, Christopher and Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {188--197},
title = {{On the impact of domain-specific knowledge in evolutionary music composition}},
url = {https://dl.acm.org/doi/abs/10.1145/3321707.3321710},
year = {2019}
}
@inproceedings{kiss2019region,
author = {Kiss, Anna and Sulyok, Csaba and Bod{\'{o}}, Zal{\'{a}}n},
booktitle = {International Conference on Artificial Neural Networks},
organization = {Springer},
pages = {581--594},
title = {{Region Prediction from Hungarian Folk Music Using Convolutional Neural Networks}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-30490-4{\_}47},
year = {2019}
}
@techreport{bocsi2011structured,
author = {B{\'{o}}csi, Botond and Csat{\'{o}}, Lehel and Peters, Jan},
institution = {Faculty of Mathematics and Computer Science, Babeș-Bolyai University},
title = {{Structured output Gaussian processes}},
year = {2011}
}
@phdthesis{jakab2012phd,
author = {Jakab, Hunor},
school = {Faculty of Mathematics and Computer Science, Babeș-Bolyai University},
title = {{Intelligent Models for Robotic Behavior, Decision Making and Environment Interaction}},
year = {2012}
}
@phdthesis{bocsi2012phd,
author = {B{\'{o}}csi, Botond},
school = {Faculty of Mathematics and Computer Science, Babeș-Bolyai University},
title = {{Model Learning for Robot Control}},
year = {2012}
}
